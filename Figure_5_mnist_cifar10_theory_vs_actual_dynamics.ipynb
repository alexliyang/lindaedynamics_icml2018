{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6: MNIST learning dynamics.\n",
    "\n",
    "This notebook provides the code to produce Figure 6 in the paper: \"Learning dynamics of linear denoising autoencoders\". (ICML 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import CIFAR10\n",
    "from collections import OrderedDict\n",
    "\n",
    "# custom imports\n",
    "from src.linear_ae_net.linear_ae_net import LinearAutoEncoder\n",
    "from src.linear_ae_net.dynamics import theoretical_learning_dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- MNIST ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# cast to tensor\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# if not exist, download mnist dataset\n",
    "train_set = MNIST(root=\"../data\", train=True, transform=trans, download=True)\n",
    "x_train = train_set.train_data.numpy()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train_mnist = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "print(x_train_mnist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0 training loss:  42.19104296875\n",
      "iteration:  0 training loss:  42.19203712843126\n",
      "iteration:  0 training loss:  42.191035160214575\n"
     ]
    }
   ],
   "source": [
    "# set parameters\n",
    "num_samples = 500\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "reg_param = 0.5\n",
    "var_param = 0.5\n",
    "reg = [0.0, reg_param, 0.0]\n",
    "var = [0.0, 0.0, var_param]\n",
    "num_trials = 3\n",
    "hidden_dim = 256\n",
    "\n",
    "mnist_models = []\n",
    "\n",
    "# convert to pytorch tensors\n",
    "x_train_mnist = torch.from_numpy(x_train_mnist)\n",
    "\n",
    "# set seed\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(321)\n",
    "\n",
    "# train autoencoder network\n",
    "for t in range(num_trials):\n",
    "    laeModel = LinearAutoEncoder()\n",
    "    laeModel.train(x_train_mnist[:num_samples,], None, input_dim=784, n_epoch=epochs, \n",
    "                   hidden_dim=hidden_dim, learning_rate=lr, reg_param=reg[t], \n",
    "                   noise='Gaussian', noise_scale=var[t], verbose=True)\n",
    "    mnist_models.append(laeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute theoretical dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MNIST dynamics\n",
    "x_train_mnist_np = x_train_mnist.cpu().numpy()\n",
    "theoretical_dynamics = theoretical_learning_dynamics(x_train_mnist_np[:num_samples, :], \n",
    "                                                             x_train_mnist_np[:num_samples, :], \n",
    "                                                             n_epoch=epochs, lr=lr, var=0, reg=0)\n",
    "theoretical_dynamics_reg = theoretical_learning_dynamics(x_train_mnist_np[:num_samples, :], \n",
    "                                                                 x_train_mnist_np[:num_samples, :], \n",
    "                                                                 n_epoch=epochs, lr=lr, var=0, \n",
    "                                                                 reg=reg_param)\n",
    "theoretical_dynamics_noise = theoretical_learning_dynamics(x_train_mnist_np[:num_samples, :], \n",
    "                                                                   x_train_mnist_np[:num_samples, :], \n",
    "                                                                   n_epoch=epochs, lr=lr, var=var_param, \n",
    "                                                                   reg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dynamics plot\n",
    "slices = (0, 3, 7, 15, 31)\n",
    "fig, [(ax1, ax2), (ax3, ax4)] = plt.subplots(2, 2, figsize=(12, 8), sharey='row', sharex='col')\n",
    "axes = [ax1, ax2]\n",
    "\n",
    "# plot theoretical dynamics\n",
    "ax1.plot(theoretical_dynamics[:, slices], c='blue', \n",
    "         label='Theory ($\\gamma = 0$)')\n",
    "ax1.plot(theoretical_dynamics_reg[:, slices], c='orange', \n",
    "         label='Theory ($\\gamma = $' + str(reg_param) + ')')\n",
    "ax2.plot(theoretical_dynamics[:, slices], c='blue', \n",
    "         label='Theory ($\\sigma^2 = 0$)')\n",
    "ax2.plot(theoretical_dynamics_noise[:, slices], c='darkgreen', \n",
    "         label='Theory ($\\sigma^2 = $' + str(var_param) + ')')\n",
    "\n",
    "# get actual dynamics\n",
    "actual_dynamics = mnist_models[0].strenghts.cpu().numpy()\n",
    "actual_dynamics_reg = mnist_models[1].strenghts.cpu().numpy()\n",
    "actual_dynamics_noise = mnist_models[2].strenghts.cpu().numpy()\n",
    "\n",
    "# plot simulated dynamics\n",
    "x_p = np.arange(0, epochs+1, 10)\n",
    "for s in slices:\n",
    "    ax1.scatter(x_p, actual_dynamics[:, s], c='blue', \n",
    "                marker='x', label='Actual ($\\gamma = 0$)')\n",
    "    ax1.scatter(x_p, actual_dynamics_reg[:, s], c='orange', \n",
    "                marker='x', label='Actual ($\\gamma = $' + str(reg_param) + ')')\n",
    "    ax2.scatter(x_p, actual_dynamics[:, s], c='blue', \n",
    "                marker='x', label='Actual ($\\sigma^2 = 0$)')\n",
    "    ax2.scatter(x_p, actual_dynamics_noise[:, s], c='darkgreen',\n",
    "                marker='x', label='Actual ($\\sigma^2 = $' + str(var_param) + ')')\n",
    "    \n",
    "    \n",
    "# set plot titles and axis labels\n",
    "ax1.set_ylabel('$w_2 \\cdot w_1$', fontsize=15)\n",
    "ax1.set_title('Weight decay')\n",
    "ax2.yaxis.set_label_position('right')\n",
    "ax2.set_ylabel('MNIST')\n",
    "\n",
    "# remove duplicates labels\n",
    "locations = ['lower right', 'lower right', 'upper right', 'upper right']\n",
    "for ax, loc in zip(axes, locations):\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = OrderedDict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), loc=loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## --- CIFAR-10 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CIFAR-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "x_train shape: (50000, 3072)\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "train_set = CIFAR10(root=\"../data\", train=True, transform=trans, download=True)\n",
    "x_train = train_set.train_data\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "x_train_cifar10 = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "print('x_train shape:', x_train_cifar10.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0 training loss:  434.49658854166665\n",
      "iteration:  0 training loss:  434.50452747529994\n",
      "iteration:  0 training loss:  434.49664074591044\n"
     ]
    }
   ],
   "source": [
    "# set parameters\n",
    "num_samples = 300\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "reg_param = 0.5\n",
    "var_param = 0.5\n",
    "reg = [0.0, reg_param, 0.0]\n",
    "var = [0.0, 0.0, var_param]\n",
    "num_trials = 3\n",
    "hidden_dim = 512\n",
    "\n",
    "cifar10_models = []\n",
    "\n",
    "# convert to pytorch tensors\n",
    "x_train_cifar10 = torch.from_numpy(x_train_cifar10)\n",
    "\n",
    "# set seed\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(321)\n",
    "\n",
    "# train autoencoder networks\n",
    "for t in range(num_trials):\n",
    "    laeModel = LinearAutoEncoder()\n",
    "    laeModel.train(x_train_cifar10[:num_samples,], None, input_dim=32*32*3, \n",
    "                   n_epoch=epochs, hidden_dim=hidden_dim, \n",
    "                   learning_rate=lr, reg_param=reg[t], \n",
    "                   noise='Gaussian', noise_scale=var[t], verbose=True)\n",
    "    cifar10_models.append(laeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute theoretical dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute CIFAR-10 dynamics\n",
    "x_train_cifar10_np = x_train_cifar10.cpu().numpy()\n",
    "theoretical_dynamics = theoretical_learning_dynamics(x_train_cifar10_np[:num_samples, :], \n",
    "                                                             x_train_cifar10_np[:num_samples, :], \n",
    "                                                             n_epoch=epochs, lr=lr, var=0, \n",
    "                                                             reg=0, u0 = 1.5e-6)\n",
    "theoretical_dynamics_reg = theoretical_learning_dynamics(x_train_cifar10_np[:num_samples, :], \n",
    "                                                                 x_train_cifar10_np[:num_samples, :], \n",
    "                                                                 n_epoch=epochs, lr=lr, var=0, \n",
    "                                                                 reg=reg_param, u0 = 1.5e-6)\n",
    "theoretical_dynamics_noise = theoretical_learning_dynamics(x_train_cifar10_np[:num_samples, :], \n",
    "                                                                   x_train_cifar10_np[:num_samples, :], \n",
    "                                                                   n_epoch=epochs, lr=lr, var=var_param, \n",
    "                                                                   reg=0, u0 = 1.5e-6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot theoretical dynamics\n",
    "ax3.plot(theoretical_dynamics[:, slices], c='blue')\n",
    "ax3.plot(theoretical_dynamics_reg[:, slices], c='orange')\n",
    "ax4.plot(theoretical_dynamics[:, slices], c='blue')\n",
    "ax4.plot(theoretical_dynamics_noise[:, slices], c='darkgreen')\n",
    "\n",
    "# get actual dynamics\n",
    "actual_dynamics = cifar10_models[0].strenghts.cpu().numpy()\n",
    "actual_dynamics_reg = cifar10_models[1].strenghts.cpu().numpy()\n",
    "actual_dynamics_noise = cifar10_models[2].strenghts.cpu().numpy()\n",
    "\n",
    "# plot simulated dynamics\n",
    "x_p = np.arange(0, epochs+1, 100)\n",
    "for s in slices:\n",
    "    ax1.scatter(x_p, actual_dynamics[:, s], c='blue', marker='x')\n",
    "    ax1.scatter(x_p, actual_dynamics_reg[:, s], c='orange', marker='x')\n",
    "    ax2.scatter(x_p, actual_dynamics[:, s], c='blue', marker='x')\n",
    "    ax2.scatter(x_p, actual_dynamics_noise[:, s], c='darkgreen',marker='x')\n",
    "\n",
    "# set plot titles and axis labels\n",
    "ax2.set_title('Noise')\n",
    "ax3.set_ylabel('$w_2 \\cdot w_1$', fontsize=15)\n",
    "ax3.set_xlabel('t (epoch)', fontsize=10)\n",
    "ax4.set_xlabel('t (epoch)', fontsize=10)\n",
    "ax4.yaxis.set_label_position('right')\n",
    "ax4.set_ylabel('CIFAR-10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
